{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9e67888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f372b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Config ---\n",
    "DATA_DIR = \"../data/processed\"\n",
    "BATCH_SIZE = 16\n",
    "LATENT_DIM = 256 #could be 128 or 256\n",
    "SPEAKER_EMB_DIM = 64 # could be 32 or 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "BETA = 0.1 # KL divergence weight\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6867f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset ---\n",
    "class MelDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.files = list(Path(data_dir).glob(\"*.pt\"))\n",
    "        self.speakers = sorted(list({f.stem.split('_')[0] for f in self.files}))\n",
    "        self.spk2idx = {spk: i for i, spk in enumerate(self.speakers)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.load(self.files[idx])\n",
    "        mel = sample['mel']\n",
    "        speaker = sample['speaker_id']\n",
    "        speaker_idx = self.spk2idx[speaker]\n",
    "        return mel, speaker_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0008f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, target_len=400):\n",
    "    mels, spk_ids = zip(*batch)\n",
    "    padded = []\n",
    "\n",
    "    for mel in mels:\n",
    "        if mel.shape[1] >= target_len:\n",
    "            mel_fixed = mel[:, :target_len]\n",
    "        else:\n",
    "            pad_width = target_len - mel.shape[1]\n",
    "            mel_fixed = F.pad(mel, (0, pad_width))  # pad on the right\n",
    "        padded.append(mel_fixed)\n",
    "\n",
    "    mels_tensor = torch.stack(padded)\n",
    "    spk_ids_tensor = torch.tensor(spk_ids)\n",
    "    return mels_tensor, spk_ids_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f05e5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model ---\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=80, latent_dim=128, speaker_emb_dim=32, num_speakers=100):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.to_mu = nn.Linear(128, latent_dim)\n",
    "        self.to_logvar = nn.Linear(128, latent_dim)\n",
    "\n",
    "        self.speaker_embed = nn.Embedding(num_speakers, speaker_emb_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim + speaker_emb_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim * 400),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def forward(self, x, speaker_id):\n",
    "        h = self.encoder(x).squeeze(-1)  # [B, 128]\n",
    "        mu = self.to_mu(h)\n",
    "        logvar = self.to_logvar(h)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        z = mu + std * torch.randn_like(std)\n",
    "        speaker_emb = self.speaker_embed(speaker_id)\n",
    "        z_cat = torch.cat([z, speaker_emb], dim=-1)\n",
    "        out = self.decoder(z_cat).view(-1, self.input_dim, 400)\n",
    "        return out, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6337772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon, x, mu, logvar, beta=BETA):\n",
    "    recon_loss = F.mse_loss(recon, x)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "    return recon_loss + beta * kl_loss, recon_loss.item(), kl_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2e8cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training ---\n",
    "def train(data_dir=\"../data/processed\",\n",
    "          latent_dim=256,\n",
    "          speaker_emb_dim=64,\n",
    "          batch_size=16,\n",
    "          epochs=20,\n",
    "          learning_rate=1e-3,\n",
    "          beta=0.01,\n",
    "          save_dir=\"../checkpoints\"):\n",
    "\n",
    "    dataset = MelDataset(data_dir)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    model = VAE(input_dim=80,\n",
    "                latent_dim=latent_dim,\n",
    "                speaker_emb_dim=speaker_emb_dim,\n",
    "                num_speakers=len(dataset.speakers)).to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, total_recon, total_kl = 0, 0, 0\n",
    "        for x, spk in tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            x, spk = x.to(DEVICE), spk.to(DEVICE)\n",
    "            recon, mu, logvar = model(x, spk)\n",
    "            loss, recon_l, kl_l = vae_loss(recon, x, mu, logvar, beta=beta)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_recon += recon_l\n",
    "            total_kl += kl_l\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Total={total_loss:.2f} | Recon={total_recon:.2f} | KL={total_kl:.2f}\")\n",
    "\n",
    "    model_name = f\"vae_lat{latent_dim}_spk{speaker_emb_dim}_ep{epochs}_beta{int(beta*1000):03}.pt\"\n",
    "    save_path = os.path.join(save_dir, model_name)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"✅ Model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7a7ed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 5521/5521 [00:47<00:00, 117.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total=3629.66 | Recon=3629.47 | KL=1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 5521/5521 [00:46<00:00, 119.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Total=3609.07 | Recon=3609.05 | KL=0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 5521/5521 [00:47<00:00, 116.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Total=3605.94 | Recon=3605.93 | KL=0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 5521/5521 [00:47<00:00, 116.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Total=3604.45 | Recon=3604.44 | KL=0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 5521/5521 [00:46<00:00, 117.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Total=3603.61 | Recon=3603.60 | KL=0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 5521/5521 [00:47<00:00, 116.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Total=3602.92 | Recon=3602.91 | KL=0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 5521/5521 [00:49<00:00, 112.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Total=3602.53 | Recon=3602.52 | KL=0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 5521/5521 [00:49<00:00, 111.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Total=3602.30 | Recon=3602.29 | KL=0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 5521/5521 [00:47<00:00, 116.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Total=3602.07 | Recon=3602.06 | KL=0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 5521/5521 [00:48<00:00, 113.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Total=3601.91 | Recon=3601.90 | KL=0.09\n",
      "✅ Model saved as vae_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f1aa760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 5521/5521 [00:52<00:00, 105.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total=3628.87 | Recon=3628.46 | KL=4.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 5521/5521 [00:46<00:00, 118.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Total=3609.66 | Recon=3609.64 | KL=0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 5521/5521 [00:47<00:00, 117.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Total=3606.77 | Recon=3606.75 | KL=0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 5521/5521 [00:47<00:00, 115.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Total=3605.33 | Recon=3605.32 | KL=0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 5521/5521 [00:47<00:00, 116.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Total=3604.61 | Recon=3604.60 | KL=0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 5521/5521 [00:47<00:00, 116.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Total=3604.27 | Recon=3604.26 | KL=0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 5521/5521 [00:48<00:00, 114.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Total=3603.97 | Recon=3603.95 | KL=0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 5521/5521 [00:47<00:00, 115.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Total=3603.71 | Recon=3603.69 | KL=0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 5521/5521 [00:47<00:00, 115.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Total=3603.51 | Recon=3603.50 | KL=0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 5521/5521 [00:47<00:00, 115.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Total=3603.45 | Recon=3603.44 | KL=0.15\n",
      "✅ Model saved to ../checkpoints\\vae_lat256_spk64_ep10_beta100.pt\n"
     ]
    }
   ],
   "source": [
    "train(latent_dim=256, speaker_emb_dim=64, epochs=10, beta=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
