{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be9dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aea998a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project root relative to notebook\n",
    "NOTEBOOK_DIR = Path(__file__).resolve().parent if '__file__' in globals() else Path().resolve()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "VCTK_ROOT = PROJECT_ROOT / \"data\" / \"raw\" / \"VCTK-Corpus\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf1c0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "VCTK_ROOT = \"../data/raw/VCTK-Corpus\"\n",
    "SAVE_DIR = \"../data/processed\"\n",
    "SAMPLE_RATE = 22050\n",
    "N_MELS = 80\n",
    "HOP_LENGTH = 256\n",
    "WIN_LENGTH = 1024\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ace9d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel-spectrogram extractor\n",
    "mel_extractor = T.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=WIN_LENGTH,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    n_mels=N_MELS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4959675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_speaker_id(path):\n",
    "    \"\"\"Extract speaker ID from filename\"\"\"\n",
    "    return path.parts[-2]  # Assuming path like VCTK-Corpus/wav48_silence_trimmed/p225/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0363b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save():\n",
    "    audio_dir = Path(VCTK_ROOT) / \"wav48_silence_trimmed\"\n",
    "    \n",
    "    if not audio_dir.exists():\n",
    "        print(f\"[ERROR] Audio directory does not exist: {audio_dir.resolve()}\")\n",
    "        return\n",
    "    \n",
    "    speaker_dirs = sorted([p for p in audio_dir.iterdir() if p.is_dir()])\n",
    "    print(f\"✅ Found {len(speaker_dirs)} speaker folders.\")\n",
    "\n",
    "    saved = 0\n",
    "    for speaker_path in tqdm(speaker_dirs, desc=\"Processing speakers\"):\n",
    "        speaker_id = speaker_path.name\n",
    "        audio_files = list(speaker_path.glob(\"*.flac\")) + list(speaker_path.glob(\"*.wav\"))\n",
    "\n",
    "        if len(audio_files) == 0:\n",
    "            print(f\"⚠️  No .flac or .wav files found in {speaker_id}\")\n",
    "            continue\n",
    "\n",
    "        for wav_file in audio_files:\n",
    "            try:\n",
    "                waveform, sr = torchaudio.load(wav_file)\n",
    "                if sr != SAMPLE_RATE:\n",
    "                    waveform = torchaudio.functional.resample(waveform, sr, SAMPLE_RATE)\n",
    "                mel = mel_extractor(waveform).squeeze(0)  # shape: [n_mels, time]\n",
    "                mel = (mel - mel.mean()) / (mel.std() + 1e-6)  # normalize\n",
    "\n",
    "                save_path = Path(SAVE_DIR) / f\"{speaker_id}_{wav_file.stem}.pt\"\n",
    "                torch.save({'mel': mel, 'speaker_id': speaker_id}, save_path)\n",
    "                saved += 1\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Failed to process {wav_file.name}: {e}\")\n",
    "\n",
    "    print(f\"\\n✅ Saved {saved} examples to {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd55c2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 110 speaker folders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing speakers: 100%|██████████| 110/110 [05:48<00:00,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved 88328 examples to ../data/processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Run the preprocessing ---\n",
    "preprocess_and_save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
